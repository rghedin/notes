---
layout: post
title: "Using ChatGPT consumes a 500 ml bottle of water; so what?"
date: 2025-02-06 15:13 -0300
---
From the obvious to the outrageous, the list of concerns about artificial intelligence has grown long since late 2022, when ChatGPT took the title of "technology of the future" from the metaverse or NFTs.

I've been thinking a lot about one of these concerns: the excessive use of energy and water needed to satisfy the insatiable thirst of big techs and startups for more money.

What is the environmental cost of outsourcing thankless tasks to ChatGPT, like writing reports that no one reads or generating a happy birthday image for that aunt you haven't spoken to in six years, in the family group chat?

Perhaps the most popular metric for this dilemma of the 2020s is [the 500&nbsp;ml water bottle for every ~50 questions to ChatGPT](https://arxiv.org/pdf/2304.03271).

Is that a lot? A little? Is the trade-off worth it? As with everything in life, the answer is: “it depends.”

Any data point, when analyzed in isolation, sounds absurd. Context is necessary. And the more context, the better. In this case, we are particularly interested in comparisons to other everyday activities we do online, which also rely on large data centers, and the cost-benefit of adding fuel (even just a few drops) to global warming in exchange for artificial verbosity and cheesy images.

\*\*\*

There are estimates that the AI race will double the tech sector's share of global energy consumption by 2026. Which… is quite a lot, considering that the sector consumed between 1–1.3% of the total back in 2022.

What can you or I do if we find this increase wasteful? To be honest, I think nothing. For us mere mortals, AI is inevitable. Like it or not, CEOs of major companies — who have the final say on the apps and websites we use daily, and how we use them — are convinced that this technology is revolutionary.

Not just convinced: they are all in, hopeful that, like any truly revolutionary technology, AI holds substantial rewards for those who master it, even if it incurs “externalities,” including frying the planet.

The inevitability is already being felt. Google and Microsoft have integrated generative AI into their productivity apps. Overnight, millions of people and businesses relying on [Microsoft&nbsp;365 (formerly Office)](https://arstechnica.com/gadgets/2025/01/home-microsoft-365-plans-use-copilot-ai-features-as-pretext-for-a-price-hike/) and [Google Workspace](https://9to5google.com/2025/01/15/google-workspace-gemini-price-increase/) gained AI assistants they didn’t ask for, which, of course, came with a considerable price increase.

Samsung has given up on improving its smartphones — [even slightly downgrading](https://www.youtube.com/watch?v=kN9YYURZD5Q) the Galaxy S25 Ultra — to focus its efforts on at least questionable AI features as highlights, in a bold attempt to convince people to upgrade their devices.

On the other side of the mobile duopoly, Apple, which refused to say “AI” and called it “machine learning” until 2022 (before ChatGPT), has embraced AI, coined an infamous pun to refer to its take on it (“Apple Intelligence”), and decided to [enable it by default in iOS&nbsp;18.3](https://www.macrumors.com/2025/01/21/macos-sequoia-15-3-apple-intelligence-opt-out/).

This is the same AI that, until this update, was [generating fake news](https://www.bbc.co.uk/news/articles/cd0elzk24dno) by “summarizing” notifications from news apps. Apple’s solution? Remove news apps from the AI summary. [Apple still sees you as a selfish asshole](https://notes.ghed.in/posts/2024/selfishness-in-ai/); that hasn’t changed.

\*\*\*

Given that it's inevitable, does it make sense to oppose the use of AI? Or rather: is it possible to stop using AI-based resources, to vote with our wallets?

For the more obvious cases, perhaps yes, and it might even be desirable since they can be tacky and/or nearly useless. An AI startup backed by billions from Amazon and Google, [Anthropic agrees](https://simonwillison.net/2025/Feb/2/anthropic/).

The problem is that, in a broader context, we are all already using “AI” to a large extent. From searching for images in Apple/Google Photos to more innocuous routines like spell check on our phones or automatic translations, everything relies on concepts and techniques that, depending on the definition (if broader), fall under the umbrella of artificial intelligence. And they offer more tangible or justifiable benefits than just removing ugly people from the background of a photo.

And it’s this perception that leads me to a fatigue that precedes the discussion itself, because it feels futile. The infamous 500&nbsp;ml water bottle that ChatGPT consumes is the new “turn off the lights to save energy,” the “take 30-second showers to avoid running out of water in the world,” meaning it doesn’t really matter whether we use ChatGPT or not because:

1. The damage is already done, and it won’t be one person or a million people trying to ignore AIs (or the obvious parts of them) that will change the course set by the industry; and
2. Even if, by some miracle, a significant boycott of AI occurs, the infrastructure that has already been built and what is currently in development won’t be dismantled due to lack of use. Instead, the industry will invent new uses because there is no idle capacity, and more importantly, no one is investing an obscene amount of money just to see if it will pan out.

One thing is a handful of startups selling empty promises backed by almost-cartoonish villains like Marc Andreessen, as we saw during the NFT craze. Another is the largest companies and investment funds on the planet pouring hundreds of billions of dollars (literally) into a technology they believe to be revolutionary.

When it reaches this stage, there are only two possible outcomes: a massive return accompanied by a true revolution, or widespread failure, regardless of who it affects. You can probably guess my hunch about which outcome we will see.

\*\*\*

It’s a bit frustrating when the responses to a dilemma echo the broad and, at this point, tired phrases like “it’s capitalism” or “these are systemic problems, we can’t do anything as individuals.” Even if that’s the case. So, I want to wrap up by providing a bit more context, on an individual level, to help ease any guilt you might feel if you want to use ChatGPT for any tedious tasks you’re asked to do at work or, let’s be realistic, to experiment with the available tools — who knows, you might find something useful?

You know those video calls, Zoom and FaceTime, that saved some semblance of sanity during the pandemic and normalized video chatting? They are among the most energy-consuming digital activities. And it doesn’t have to be that way if we’re willing to turn off the video and just use audio, like we did before the pandemic. This simple gesture [saves 96% of the carbon emissions](https://foundation.mozilla.org/en/blog/ai-internet-carbon-footprint/) from a video call — or, in this case, a call.

Before you delete the Zoom app from your phone, consider that, even if you don’t turn off the video for any reason, a video call is obviously much more economical and energy-efficient than flying and then taking an Uber or renting a car to have a face-to-face conversation with someone on the other side of the country.

You know what consumes way more energy than hundreds or thousands of silly responses and bad code generated by ChatGPT? [Video streaming](https://andymasley.substack.com/p/individual-ai-use-is-not-bad-for). Are we all going to cancel Netflix and YouTube and go back to the 1990s internet, which was all text-based, and to DVD rental stores? Yeah, I, along with Blockbuster, don’t think so.

For my part, I believe that directing (our!) energy toward actors, instances, and problems with a higher chance of yielding greater (systemic!) returns is a more promising path. How? I don’t know. I leave that question (and my support) to activists, scientists, politicians committed to the environment, and anyone else who knows better to help. I’m just an average guy writing on a blog that almost no one reads.

Let’s fight against the establishment of data centers in areas already suffering from drought, or [push big tech companies to be more transparent](https://www.nature.com/articles/s41545-021-00101-w) in their environmental reports and more efficient in water reuse and developing techniques to mitigate environmental impact.

Regardless of what we think about AIs in general, and generative AIs in particular — whether they’re tacky, unethical, super cool, or revolutionary —, I know that harassing those who use them won’t solve the problem. I mean, for the use itself. Making fun of someone who claims to be the author of poems generated by ChatGPT, well, I think that’s fair game.